# ğŸ¤– PHáº¦N 7: NHáº¬P MÃ”N KHOA Há»ŒC Dá»® LIá»†U VÃ€ MACHINE LEARNING

## ğŸ¯ Má»¥c tiÃªu tá»•ng quÃ¡t

- Hiá»ƒu rÃµ vá»‹ trÃ­ cá»§a Machine Learning trong lÄ©nh vá»±c AI vÃ  Khoa há»c Dá»¯ liá»‡u.
- Náº¯m vá»¯ng quy trÃ¬nh chuáº©n Ä‘á»ƒ thá»±c hiá»‡n má»™t dá»± Ã¡n Machine Learning tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i.
- XÃ¢y dá»±ng vÃ  Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c cÃ¡c mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n cho cáº£ bÃ i toÃ¡n há»“i quy vÃ  phÃ¢n loáº¡i báº±ng Scikit-learn.
- Ãp dá»¥ng Ä‘Æ°á»£c thuáº­t toÃ¡n gom cá»¥m Ä‘á»ƒ khÃ¡m phÃ¡ cÃ¡c nhÃ³m tiá»m áº©n trong dá»¯ liá»‡u.
- CÃ³ cÃ¡i nhÃ¬n tá»•ng quan vá» Deep Learning vÃ  cÃ¡c thÆ° viá»‡n phá»• biáº¿n nhÆ° TensorFlow/Keras.
- HoÃ n thÃ nh má»™t dá»± Ã¡n phÃ¢n loáº¡i hoÃ n chá»‰nh, giáº£i quyáº¿t má»™t bÃ i toÃ¡n kinh doanh thá»±c táº¿.

## ğŸ§‘â€ğŸ« BÃ i 1: Tá»•ng quan vÃ  Quy trÃ¬nh lÃ m viá»‡c

### AI, ML, vÃ  Khoa há»c Dá»¯ liá»‡u

- **AI (TrÃ­ tuá»‡ NhÃ¢n táº¡o)**: LÃ  má»¥c tiÃªu lá»›n nháº±m táº¡o ra cÃ¡c há»‡ thá»‘ng thÃ´ng minh.
- **ML (Há»c mÃ¡y)**: LÃ  má»™t phÆ°Æ¡ng phÃ¡p cá»‘t lÃµi cá»§a AI, táº­p trung vÃ o viá»‡c cho mÃ¡y tÃ­nh "há»c" tá»« dá»¯ liá»‡u.
- **Khoa há»c Dá»¯ liá»‡u**: LÃ  má»™t lÄ©nh vá»±c liÃªn ngÃ nh, sá»­ dá»¥ng ML vÃ  cÃ¡c cÃ´ng cá»¥ khÃ¡c Ä‘á»ƒ trÃ­ch xuáº¥t kiáº¿n thá»©c tá»« dá»¯ liá»‡u.

### Quy trÃ¬nh má»™t dá»± Ã¡n Machine Learning

SÆ¡ Ä‘á»“ quy trÃ¬nh tiÃªu chuáº©n:

```text
+----------------+   +-----------+   +---------------+   +------------+   +-----------+   +-----------+
|   XÃ¡c Ä‘á»‹nh     |   | Thu tháº­p  |   | Tiá»n xá»­ lÃ½ &  |   | Lá»±a chá»n & |   |  ÄÃ¡nh giÃ¡  |   | Tinh chá»‰nh |
|   BÃ i toÃ¡n     |-->|  Dá»¯ liá»‡u  |-->|  KhÃ¡m phÃ¡     |-->|  Huáº¥n luyá»‡n |-->|  MÃ´ hÃ¬nh  |-->| & Triá»ƒn khai|
| (Problem Def.) |   | (Data Acq)|   |  (EDA & Prep) |   |  (Modeling)  |   | (Evaluation)|   | (Deployment)|
+----------------+   +-----------+   +---------------+   +------------+   +-----------+   +-----------+
```

ChÃºng ta sáº½ Ä‘i theo quy trÃ¬nh nÃ y trong suá»‘t pháº§n há»c.

### Giá»›i thiá»‡u Scikit-learn

- LÃ  thÆ° viá»‡n ML phá»• biáº¿n nháº¥t cho cÃ¡c tÃ¡c vá»¥ ML "cá»• Ä‘iá»ƒn" (khÃ´ng pháº£i Deep Learning).
- Cung cáº¥p má»™t API (giao diá»‡n) nháº¥t quÃ¡n vÃ  Ä‘Æ¡n giáº£n:
  - `model.fit(X, y)`: Huáº¥n luyá»‡n (dáº¡y) mÃ´ hÃ¬nh.
  - `model.predict(X_new)`: ÄÆ°a ra dá»± Ä‘oÃ¡n cho dá»¯ liá»‡u má»›i.
  - `model.score(X, y)`: ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh.

## ğŸ§‘â€ğŸ« BÃ i 2: Há»c cÃ³ giÃ¡m sÃ¡t (Supervised Learning) - Há»“i quy (Regression)

### BÃ i toÃ¡n Há»“i quy lÃ  gÃ¬?

- **Má»¥c tiÃªu**: Dá»± Ä‘oÃ¡n má»™t giÃ¡ trá»‹ **liÃªn tá»¥c** (sá»‘).
- **VÃ­ dá»¥**: Dá»± Ä‘oÃ¡n giÃ¡ nhÃ , dá»± Ä‘oÃ¡n cÃ¢n náº·ng dá»±a trÃªn chiá»u cao, dá»± Ä‘oÃ¡n doanh sá»‘ bÃ¡n hÃ ng.
- **YÃªu cáº§u**: Dá»¯ liá»‡u huáº¥n luyá»‡n pháº£i cÃ³ "nhÃ£n" (giÃ¡ trá»‹ thá»±c táº¿ Ä‘á»ƒ so sÃ¡nh).

### MÃ´ hÃ¬nh Há»“i quy Tuyáº¿n tÃ­nh (Linear Regression)

- ÄÃ¢y lÃ  mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n vÃ  dá»… diá»…n giáº£i nháº¥t. NÃ³ cá»‘ gáº¯ng tÃ¬m má»™t Ä‘Æ°á»ng tháº³ng (hoáº·c má»™t siÃªu pháº³ng) phÃ¹ há»£p nháº¥t vá»›i dá»¯ liá»‡u.

**VÃ­ dá»¥ code:**

```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# Dá»¯ liá»‡u giáº£ Ä‘á»‹nh: diá»‡n tÃ­ch nhÃ  (m2) vÃ  giÃ¡ nhÃ  (tá»· VNÄ)
X = np.array([[50], [60], [70], [80], [100]]) # Features (diá»‡n tÃ­ch)
y = np.array([2.5, 3.1, 3.4, 4.2, 5.0])       # Target (giÃ¡)

# 1. Chia dá»¯ liá»‡u
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 2. Táº¡o vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh
model = LinearRegression()
model.fit(X_train, y_train)

# 3. Dá»± Ä‘oÃ¡n
# Dá»± Ä‘oÃ¡n giÃ¡ cá»§a má»™t cÄƒn nhÃ  90m2
predicted_price = model.predict([[90]])
print(f"GiÃ¡ nhÃ  90m2 Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ : {predicted_price[0]:.2f} tá»· VNÄ")
```

### ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh Há»“i quy (MSE, RÂ²)

- **Mean Squared Error (MSE)**: Trung bÃ¬nh cá»§a bÃ¬nh phÆ°Æ¡ng cÃ¡c sai sá»‘. Con sá»‘ nÃ y cÃ ng nhá» cÃ ng tá»‘t.
- **R-squared (RÂ²)**: Cho biáº¿t má»©c Ä‘á»™ (tá»« 0 Ä‘áº¿n 1) mÃ  cÃ¡c features giáº£i thÃ­ch Ä‘Æ°á»£c sá»± biáº¿n thiÃªn cá»§a target. `RÂ² = 0.8` cÃ³ nghÄ©a lÃ  mÃ´ hÃ¬nh giáº£i thÃ­ch Ä‘Æ°á»£c 80% sá»± biáº¿n Ä‘á»™ng cá»§a giÃ¡ nhÃ . CÃ ng gáº§n 1 cÃ ng tá»‘t.

```python
from sklearn.metrics import mean_squared_error, r2_score

# ÄÃ¡nh giÃ¡ trÃªn táº­p test
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"R-squared (RÂ²): {r2:.2f}")
```

## ğŸ§‘â€ğŸ« BÃ i 3: Há»c cÃ³ giÃ¡m sÃ¡t (Supervised Learning) - PhÃ¢n loáº¡i (Classification)

### BÃ i toÃ¡n PhÃ¢n loáº¡i lÃ  gÃ¬?

- **Má»¥c tiÃªu**: Dá»± Ä‘oÃ¡n má»™t nhÃ£n **rá»i ráº¡c** (má»™t lá»›p cá»¥ thá»ƒ).
- **VÃ­ dá»¥**: Email lÃ  "spam" hay "khÃ´ng spam"? Giao dá»‹ch cÃ³ "gian láº­n" hay "khÃ´ng"? Bá»©c áº£nh chá»©a "chÃ³" hay "mÃ¨o"?
- CÃ³ thá»ƒ lÃ  phÃ¢n loáº¡i nhá»‹ phÃ¢n (2 lá»›p) hoáº·c Ä‘a lá»›p (> 2 lá»›p).

### CÃ¡c mÃ´ hÃ¬nh PhÃ¢n loáº¡i phá»• biáº¿n

- **Logistic Regression**: DÃ¹ng Ä‘á»ƒ phÃ¢n loáº¡i nhá»‹ phÃ¢n, dá»± Ä‘oÃ¡n xÃ¡c suáº¥t má»™t Ä‘iá»ƒm dá»¯ liá»‡u thuá»™c vá» lá»›p 1.
- **Decision Tree (CÃ¢y quyáº¿t Ä‘á»‹nh)**: MÃ´ hÃ¬nh dá»… hiá»ƒu, hoáº¡t Ä‘á»™ng báº±ng cÃ¡ch liÃªn tá»¥c chia dá»¯ liá»‡u dá»±a trÃªn cÃ¡c cÃ¢u há»i cÃ³/khÃ´ng vá» cÃ¡c feature.

**VÃ­ dá»¥ code vá»›i CÃ¢y quyáº¿t Ä‘á»‹nh:**

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn import datasets

# Táº£i bá»™ dá»¯ liá»‡u hoa Iris ná»•i tiáº¿ng
iris = datasets.load_iris()
X = iris.data
y = iris.target

# 1. Chia dá»¯ liá»‡u
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 2. Táº¡o vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh
clf = DecisionTreeClassifier()
clf.fit(X_train, y_train)

# 3. Dá»± Ä‘oÃ¡n
predictions = clf.predict(X_test)
```

### ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh PhÃ¢n loáº¡i (Accuracy, Confusion Matrix)

- **Accuracy (Äá»™ chÃ­nh xÃ¡c)**: Tá»· lá»‡ tá»•ng sá»‘ dá»± Ä‘oÃ¡n Ä‘Ãºng. `accuracy = (Sá»‘ dá»± Ä‘oÃ¡n Ä‘Ãºng) / (Tá»•ng sá»‘ dá»± Ä‘oÃ¡n)`.
- **Confusion Matrix (Ma tráº­n nháº§m láº«n)**: Má»™t báº£ng 2x2 (cho bÃ i toÃ¡n nhá»‹ phÃ¢n) cho tháº¥y:
  - **True Positives (TP)**: Dá»± Ä‘oÃ¡n lÃ  "CÃ³", thá»±c táº¿ lÃ  "CÃ³".
  - **True Negatives (TN)**: Dá»± Ä‘oÃ¡n lÃ  "KhÃ´ng", thá»±c táº¿ lÃ  "KhÃ´ng".
  - **False Positives (FP)**: Dá»± Ä‘oÃ¡n lÃ  "CÃ³", thá»±c táº¿ lÃ  "KhÃ´ng" (Lá»—i loáº¡i I).
  - **False Negatives (FN)**: Dá»± Ä‘oÃ¡n lÃ  "KhÃ´ng", thá»±c táº¿ lÃ  "CÃ³" (Lá»—i loáº¡i II).

```python
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# ÄÃ¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c
acc = accuracy_score(y_test, predictions)
print(f"Accuracy: {acc:.2f}")

# Váº½ ma tráº­n nháº§m láº«n
cm = confusion_matrix(y_test, predictions)
sns.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
```

## ğŸ§‘â€ğŸ« BÃ i 4: Há»c khÃ´ng giÃ¡m sÃ¡t (Unsupervised Learning) - Gom cá»¥m (Clustering)

### Khi nÃ o cáº§n Há»c khÃ´ng giÃ¡m sÃ¡t?

- Khi dá»¯ liá»‡u cá»§a báº¡n **khÃ´ng cÃ³ nhÃ£n** (khÃ´ng cÃ³ cá»™t káº¿t quáº£ `y`).
- **Má»¥c tiÃªu**: Tá»± Ä‘á»™ng khÃ¡m phÃ¡ cÃ¡c cáº¥u trÃºc, cÃ¡c máº«u hoáº·c cÃ¡c nhÃ³m (cá»¥m) tá»± nhiÃªn trong dá»¯ liá»‡u.
- **á»¨ng dá»¥ng**: PhÃ¢n khÃºc khÃ¡ch hÃ ng, há»‡ thá»‘ng gá»£i Ã½, phÃ¡t hiá»‡n báº¥t thÆ°á»ng.

### Thuáº­t toÃ¡n K-Means Clustering

- LÃ  thuáº­t toÃ¡n gom cá»¥m phá»• biáº¿n vÃ  Ä‘Æ¡n giáº£n nháº¥t.
- Báº¡n cáº§n chá»‰ Ä‘á»‹nh trÆ°á»›c sá»‘ cá»¥m (K) mÃ  báº¡n muá»‘n tÃ¬m.
- Thuáº­t toÃ¡n sáº½ cá»‘ gáº¯ng phÃ¢n chia cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u vÃ o K cá»¥m sao cho cÃ¡c Ä‘iá»ƒm trong cÃ¹ng má»™t cá»¥m gáº§n nhau nháº¥t cÃ³ thá»ƒ.

**VÃ­ dá»¥ code:**

```python
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs

# Táº¡o dá»¯ liá»‡u giáº£ láº­p cÃ³ 3 cá»¥m
X, _ = make_blobs(n_samples=300, centers=3, cluster_std=0.8, random_state=42)

# Táº¡o vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh K-Means vá»›i K=3
kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
kmeans.fit(X)

# Láº¥y nhÃ£n cá»¥m cho má»—i Ä‘iá»ƒm dá»¯ liá»‡u
labels = kmeans.labels_
centers = kmeans.cluster_centers_

# Trá»±c quan hÃ³a káº¿t quáº£
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', s=50, alpha=0.7)
plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, marker='X')
plt.title('K-Means Clustering')
plt.show()
```

## ğŸ§‘â€ğŸ« BÃ i 5: Giá»›i thiá»‡u vá» Deep Learning vÃ  Máº¡ng Neural

### Khi nÃ o Machine Learning lÃ  khÃ´ng Ä‘á»§?

- CÃ¡c mÃ´ hÃ¬nh ML truyá»n thá»‘ng hoáº¡t Ä‘á»™ng tá»‘t vá»›i dá»¯ liá»‡u cÃ³ cáº¥u trÃºc (dáº¡ng báº£ng).
- Tuy nhiÃªn, chÃºng gáº·p khÃ³ khÄƒn vá»›i dá»¯ liá»‡u phi cáº¥u trÃºc vÃ  phá»©c táº¡p nhÆ° **hÃ¬nh áº£nh, Ã¢m thanh, vÄƒn báº£n**. ÄÃ¢y lÃ  lÃºc Deep Learning tá»a sÃ¡ng.

### Máº¡ng Neural nhÃ¢n táº¡o lÃ  gÃ¬?

- Láº¥y cáº£m há»©ng tá»« nÃ£o bá»™, máº¡ng neural gá»“m cÃ¡c "neuron" Ä‘Æ°á»£c káº¿t ná»‘i vá»›i nhau trong cÃ¡c "lá»›p".
- Dá»¯ liá»‡u Ä‘i vÃ o lá»›p Ä‘áº§u vÃ o (input layer), Ä‘i qua má»™t hoáº·c nhiá»u lá»›p áº©n (hidden layers) Ä‘á»ƒ xá»­ lÃ½, vÃ  Ä‘i ra á»Ÿ lá»›p Ä‘áº§u ra (output layer) Ä‘á»ƒ cho káº¿t quáº£.
- **Deep Learning** lÃ  viá»‡c sá»­ dá»¥ng cÃ¡c máº¡ng neural cÃ³ nhiá»u lá»›p áº©n (deep networks).

### Giá»›i thiá»‡u TensorFlow vÃ  Keras

- **TensorFlow**: LÃ  má»™t ná»n táº£ng mÃ£ nguá»“n má»Ÿ máº¡nh máº½ cho ML vÃ  DL do Google phÃ¡t triá»ƒn.
- **Keras**: LÃ  má»™t API báº­c cao, cá»±c ká»³ thÃ¢n thiá»‡n vá»›i ngÆ°á»i dÃ¹ng, Ä‘Æ°á»£c tÃ­ch há»£p sáºµn trong TensorFlow. Keras giÃºp viá»‡c xÃ¢y dá»±ng má»™t máº¡ng neural trá»Ÿ nÃªn Ä‘Æ¡n giáº£n nhÆ° xáº¿p cÃ¡c khá»‘i Lego.

**VÃ­ dá»¥ xÃ¢y dá»±ng má»™t máº¡ng neural Ä‘Æ¡n giáº£n vá»›i Keras:**

```python
import tensorflow as tf
from tensorflow import keras

# XÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh tuáº§n tá»±
model = keras.Sequential([
    # Lá»›p Ä‘áº§u vÃ o, lÃ m pháº³ng áº£nh 28x28 thÃ nh vector 784
    keras.layers.Flatten(input_shape=(28, 28)), 
    # Lá»›p áº©n vá»›i 128 neurons, hÃ m kÃ­ch hoáº¡t 'relu'
    keras.layers.Dense(128, activation='relu'), 
    # Lá»›p Ä‘áº§u ra vá»›i 10 neurons (cho 10 chá»¯ sá»‘ 0-9)
    keras.layers.Dense(10, activation='softmax')
])

# BiÃªn dá»‹ch mÃ´ hÃ¬nh
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# (Sau Ä‘Ã³ sáº½ lÃ  bÆ°á»›c huáº¥n luyá»‡n model.fit(X_train, y_train, ...))
```

## ğŸ§ª BÃ€I Táº¬P Lá»šN CUá»I PHáº¦N: Dá»± Ä‘oÃ¡n KhÃ¡ch hÃ ng rá»i bá» (Customer Churn Prediction)

### MÃ´ táº£ bÃ i toÃ¡n

Má»™t cÃ´ng ty viá»…n thÃ´ng muá»‘n dá»± Ä‘oÃ¡n nhá»¯ng khÃ¡ch hÃ ng nÃ o cÃ³ kháº£ nÄƒng sáº½ há»§y há»£p Ä‘á»“ng (churn) trong tÆ°Æ¡ng lai gáº§n. Viá»‡c nÃ y giÃºp cÃ´ng ty cÃ³ thá»ƒ Ä‘Æ°a ra cÃ¡c chÆ°Æ¡ng trÃ¬nh Æ°u Ä‘Ã£i Ä‘á»ƒ giá»¯ chÃ¢n há». Báº¡n Ä‘Æ°á»£c cung cáº¥p má»™t bá»™ dá»¯ liá»‡u vá» khÃ¡ch hÃ ng, bao gá»“m thÃ´ng tin nhÃ¢n kháº©u há»c, cÃ¡c dá»‹ch vá»¥ há» sá»­ dá»¥ng vÃ  liá»‡u há» cÃ³ rá»i bá» hay khÃ´ng.

(Gá»£i Ã½ bá»™ dá»¯ liá»‡u: [Telco Customer Churn tá»« Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)).

### YÃªu cáº§u

Thá»±c hiá»‡n toÃ n bá»™ quy trÃ¬nh cá»§a má»™t dá»± Ã¡n Machine Learning trong Jupyter Notebook.

1. **PhÃ¢n tÃ­ch KhÃ¡m phÃ¡ Dá»¯ liá»‡u (EDA)**:
    - Äá»c vÃ  lÃ m sáº¡ch dá»¯ liá»‡u (xá»­ lÃ½ giÃ¡ trá»‹ thiáº¿u náº¿u cÃ³).
    - Sá»­ dá»¥ng cÃ¡c kiáº¿n thá»©c tá»« Pháº§n 6 Ä‘á»ƒ trá»±c quan hÃ³a dá»¯ liá»‡u, tÃ¬m hiá»ƒu má»‘i quan há»‡ giá»¯a cÃ¡c Ä‘áº·c trÆ°ng vÃ  biáº¿n `Churn` (vÃ­ dá»¥: loáº¡i há»£p Ä‘á»“ng, thá»i gian gáº¯n bÃ³ áº£nh hÆ°á»Ÿng Ä‘áº¿n tá»· lá»‡ rá»i bá» nhÆ° tháº¿ nÃ o?).

2. **Tiá»n xá»­ lÃ½ Dá»¯ liá»‡u**:
    - Chuyá»ƒn Ä‘á»•i cÃ¡c cá»™t dáº¡ng chá»¯ (categorical) thÃ nh dáº¡ng sá»‘ mÃ  mÃ´ hÃ¬nh cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c (sá»­ dá»¥ng `pd.get_dummies` hoáº·c `OneHotEncoder`).
    - Chuáº©n hÃ³a (scale) cÃ¡c cá»™t sá»‘ Ä‘á»ƒ chÃºng cÃ³ cÃ¹ng thang Ä‘o (sá»­ dá»¥ng `StandardScaler` hoáº·c `MinMaxScaler`).

3. **XÃ¢y dá»±ng vÃ  Huáº¥n luyá»‡n MÃ´ hÃ¬nh**:
    - Chia dá»¯ liá»‡u thÃ nh táº­p train vÃ  táº­p test.
    - Thá»­ nghiá»‡m Ã­t nháº¥t 2 mÃ´ hÃ¬nh phÃ¢n loáº¡i khÃ¡c nhau (vÃ­ dá»¥: Logistic Regression vÃ  Decision Tree/Random Forest).

4. **ÄÃ¡nh giÃ¡ MÃ´ hÃ¬nh**:
    - TÃ­nh toÃ¡n `accuracy` cho cáº£ hai mÃ´ hÃ¬nh.
    - Váº½ `confusion matrix` Ä‘á»ƒ hiá»ƒu rÃµ hÆ¡n vá» hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh tá»‘t nháº¥t. ChÃº Ã½ Ä‘áº¿n sá»‘ lÆ°á»£ng khÃ¡ch hÃ ng bá»‹ dá»± Ä‘oÃ¡n sai lÃ  "KhÃ´ng rá»i bá»" trong khi thá»±c táº¿ há» "CÃ³ rá»i bá»" (False Negatives).
    - Dá»±a trÃªn káº¿t quáº£, báº¡n sáº½ Ä‘á» xuáº¥t mÃ´ hÃ¬nh nÃ o cho cÃ´ng ty? Táº¡i sao?

5. **Káº¿t luáº­n**: TÃ³m táº¯t káº¿t quáº£ vÃ  Ä‘Æ°a ra má»™t vÃ i gá»£i Ã½ cho phÃ­a kinh doanh dá»±a trÃªn nhá»¯ng gÃ¬ mÃ´ hÃ¬nh Ä‘Ã£ há»c Ä‘Æ°á»£c (vÃ­ dá»¥: "Nhá»¯ng khÃ¡ch hÃ ng cÃ³ há»£p Ä‘á»“ng theo thÃ¡ng vÃ  sá»­ dá»¥ng dá»‹ch vá»¥ Internet cÃ¡p quang cÃ³ tá»· lá»‡ rá»i bá» cao nháº¥t. Cáº§n cÃ³ chÃ­nh sÃ¡ch chÄƒm sÃ³c Ä‘áº·c biá»‡t cho nhÃ³m nÃ y.").
